{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import tqdm\n",
    "import timeit\n",
    "import textwrap\n",
    "import sklearn\n",
    "import xgboost\n",
    "import unittest\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import skew\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/delst/OneDrive - Queen Mary, University of London/Desktop/VSCode/Advanced_Projects/Uber_Demand_Project/data_archive/*.csv'\n",
    "input_files = glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/delst/OneDrive - Queen Mary, University of London/Desktop/VSCode/Advanced_Projects/Uber_Demand_Project/data_archive\\uber.csv\n",
      "Total number of files loaded: 1\n"
     ]
    }
   ],
   "source": [
    "def file_load(path):\n",
    "        \n",
    "    for i, file in enumerate(input_files):\n",
    "        print(file)\n",
    "        globals()[f'df{i+1}'] = pd.read_csv(input_files[i])\n",
    "    print(f'Total number of files loaded: {len(input_files)}')\n",
    "    \n",
    "file_load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store = [eval(f'df{i+1}') for i in range(len(input_files))]   # Dataframe preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, threshold):\n",
    "        self.data = data\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def data_transform(self):\n",
    "        self.data['pickup_datetime'] = pd.to_datetime(self.data['pickup_datetime']).dt.tz_localize(None)\n",
    "        self.data['pickup_datetime'] = self.data['pickup_datetime'].dt.floor('H')\n",
    "        \n",
    "        self.data['Label_Hour'] = self.data['pickup_datetime'].dt.hour\n",
    "        self.data['Label_Date'] = self.data['pickup_datetime'].dt.date\n",
    "\n",
    "        self.data['day_name'] = pd.to_datetime(self.data['pickup_datetime']).dt.day_name()\n",
    "        self.data['day_of_the_week'] = pd.to_datetime(self.data['pickup_datetime']).dt.weekday\n",
    "        return self.data\n",
    "            \n",
    "    def data_remove_outliers(self):\n",
    "        self.data = self.data[(np.abs(stats.zscore(self.data['passenger_count'])) < 2)]\n",
    "        self.data = self.data[(np.abs(stats.zscore(self.data['fare_amount'])) < 2)]\n",
    "        return self.data\n",
    "\n",
    "    def data_clean(self):\n",
    "        self.data['fare_amount'] = abs(self.data.fare_amount)\n",
    "        self.data.passenger_count.replace(0, 1, inplace=True)\n",
    "        self.data.fare_amount.replace(0, 1, inplace=True)\n",
    "        self.data = self.data.dropna()\n",
    "        return self.data\n",
    "    \n",
    "    def winsorization(self):\n",
    "        median = self.data['sPED'].median()\n",
    "        lower_quantile = self.data['sPED'].quantile(self.threshold)\n",
    "        upper_quantile = self.data['sPED'].quantile(1-self.threshold)\n",
    "        self.data['sPED'][self.data['sPED'] < lower_quantile] = -1*median\n",
    "        self.data['sPED'][self.data['sPED'] > upper_quantile] = median\n",
    "        return self.data\n",
    "    \n",
    "    def index_set(self):\n",
    "        self.data = self.data.set_index('pickup_datetime')\n",
    "        self.data.index = self.data.index.strftime('%Y-%m-%d-%H')\n",
    "        return self.data\n",
    "\n",
    "class GroupClass:\n",
    "    def __init__(self, data, col_group):\n",
    "        self.data = data\n",
    "        self.col_group = col_group\n",
    "    \n",
    "    def group_by_hour(self, col_group):\n",
    "        self.data = self.data[col_group].groupby(['pickup_datetime'])['passenger_count','fare_amount'].agg({'passenger_count':'mean','fare_amount':'mean'}).reset_index()\n",
    "        return self.data\n",
    "    \n",
    "    def group_by_day(self, col_group):\n",
    "        self.data = self.data[col_group].groupby(['Label_Date'])['passenger_count','fare_amount'].agg({'passenger_count':'mean','fare_amount':'mean'}).reset_index()\n",
    "        return self.data\n",
    "    \n",
    "class FeatureExtraction:\n",
    "    def __init__(self, data, col_feature, n_window):\n",
    "        self.data = data\n",
    "        self.col_feature = col_feature\n",
    "        self.n_window = n_window\n",
    "\n",
    "    def calc_pct_change(self, col_feature):\n",
    "        for col in col_feature:\n",
    "            self.data[col + '_pct_change'] = self.data[col].pct_change()\n",
    "        return self.data\n",
    "    \n",
    "    def calc_sma(self, col, n_window):\n",
    "        self.data[col + '_sma'] = self.data[col].rolling(window=self.n_window).mean()\n",
    "        return self.data\n",
    "        \n",
    "    def calc_ema(self, col, n_window):\n",
    "        self.data[col + '_ema'] = self.data[col].ewm(span=n_window, adjust=False).mean()\n",
    "        return self.data\n",
    "        \n",
    "    def calc_sma_PED(self):\n",
    "        self.data['sPED'] = self.data.passenger_count_pct_change_sma / self.data.fare_amount_pct_change_sma\n",
    "        return self.data\n",
    "        \n",
    "    def calc_ema_PED(self):\n",
    "        self.data['ePED'] = self.data.passenger_count_pct_change_ema / self.data.fare_amount_pct_change_ema\n",
    "        return self.data\n",
    "\n",
    "class ModelSelection:\n",
    "    def __init__(self, data, input_columns, target_column, cv_splits, test_split):\n",
    "        self.data = data\n",
    "        self.input_columns = input_columns\n",
    "        self.target_column = target_column\n",
    "        self.cv_splits = cv_splits\n",
    "        self.test_split = test_split\n",
    "        # self.models = [DecisionTreeRegressor(random_state=0), LinearRegression(),\n",
    "        #                RandomForestRegressor(), \n",
    "        #                SVR(C=1.0, epsilon=0.2), \n",
    "        #                xgboost.XGBRegressor(n_estimators=100, max_depth=5, eta=0.1, subsample=1-test_split)]\n",
    "        self.models = {\n",
    "            'DecisionTreeRegressor': DecisionTreeRegressor(random_state=0),\n",
    "            'LinearRegression': LinearRegression(),\n",
    "            'RandomForestRegressor': RandomForestRegressor(), \n",
    "            'SVR': SVR(C=1.0, epsilon=0.2), \n",
    "            'XGBRegressor': xgboost.XGBRegressor(n_estimators=100, max_depth=5, eta=0.1, subsample=1-test_split)\n",
    "        }\n",
    "        \n",
    "    def split_dataset(self):\n",
    "        input_features = self.data.drop(input_columns, axis=1)\n",
    "        target_variable = self.data[target_column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(input_features, target_variable, shuffle=False, test_size=test_split)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def model_evaluation(self, model, X_train, y_train, cv_splits):\n",
    "        std_clf = make_pipeline(StandardScaler(), model)\n",
    "\n",
    "        r2_scores = []\n",
    "        mae_scores = []\n",
    "        rmse_scores = []\n",
    "\n",
    "        kf = KFold(n_splits=cv_splits, shuffle=False)\n",
    "        for train_index, test_index in kf.split(X_train):\n",
    "            X_train_cv, X_test_cv = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "            y_train_cv, y_test_cv = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "            std_clf.fit(X_train_cv, y_train_cv)\n",
    "            y_pred = std_clf.predict(X_test_cv)\n",
    "\n",
    "            r2_scores.append(r2_score(y_test_cv, y_pred))\n",
    "            mae_scores.append(mean_absolute_error(y_test_cv, y_pred))\n",
    "            rmse_scores.append(np.sqrt(mean_squared_error(y_test_cv, y_pred)))\n",
    "\n",
    "        return {\"Mean R^2\": sum(r2_scores) / cv_splits, \n",
    "                \"Mean MAE\": sum(mae_scores) / cv_splits,\n",
    "                \"Mean RMSE\": sum(rmse_scores) / cv_splits}\n",
    "        \n",
    "    def run_model_evaluation(self):\n",
    "        X_train, X_test, y_train, y_test = self.split_dataset()\n",
    "        results = {}\n",
    "        for model_name, model in self.models.items():\n",
    "            results[model_name] = self.model_evaluation(model, X_train, y_train, cv_splits)\n",
    "        return results\n",
    "    \n",
    "    def select_initial_model(self):\n",
    "        X_train, X_test, y_train, y_test = self.split_dataset()\n",
    "        best_model = None\n",
    "        best_score = 0\n",
    "        for model_name, model in self.models.items():\n",
    "            # Define hyperparameters for grid search\n",
    "            if model_name == 'DecisionTreeRegressor':\n",
    "                params = {'max_depth': [5, 10, 15]}\n",
    "            elif model_name == 'LinearRegression':\n",
    "                params = {'fit_intercept': [True, False]}\n",
    "            elif model_name == 'RandomForestRegressor':\n",
    "                params = {'n_estimators': [50, 100, 150], 'max_depth': [5, 10, 15]}\n",
    "            elif model_name == 'SVR':\n",
    "                params = {'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1]}\n",
    "            elif model_name == 'XGBRegressor':\n",
    "                params = {'max_depth': [3, 5, 7], 'n_estimators': [50, 100, 150]}\n",
    "                \n",
    "            # Perform grid search\n",
    "            grid = GridSearchCV(estimator=model, param_grid=params, cv=self.cv_splits, n_jobs=-1)\n",
    "            grid.fit(X_train, y_train)\n",
    "            \n",
    "            # Determine if this model is the best so far\n",
    "            if grid.best_score_ > best_score:\n",
    "                best_score = grid.best_score_\n",
    "                best_model = grid.best_estimator_\n",
    "                best_params = grid.best_params_\n",
    "        \n",
    "        best_model_name = type(best_model).__name__\n",
    "        if best_model_name == 'XGBRegressor':\n",
    "            model_class = xgboost.XGBRegressor\n",
    "        else:\n",
    "            model_class = getattr(sklearn.ensemble, best_model_name)\n",
    "        selected_model = model_class(**best_params)\n",
    "        \n",
    "        print('\\n')\n",
    "        print(\"Selected model: {}\".format(type(best_model).__name__))\n",
    "        print(\"Hyperparameters: {}\".format(best_params))\n",
    "        print(\"Model score: {}\".format(best_score))\n",
    "        print('\\n')\n",
    "\n",
    "        return selected_model\n",
    "            \n",
    "class Model:\n",
    "    def __init__(self, data, X_train, y_train, selected_model, cv_splits):\n",
    "        self.data = data\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.selected_model = selected_model\n",
    "        self.cv_splits = cv_splits\n",
    "\n",
    "    def train_model(self):\n",
    "        std_clf = make_pipeline(StandardScaler(), self.selected_model)\n",
    "        std_clf.fit(X_train_cv, y_train_cv)\n",
    "        self.std_clf = std_clf\n",
    "\n",
    "        kf = KFold(n_splits=self.cv_splits, shuffle=False)\n",
    "        train_results = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(kf.split(self.X_train)):\n",
    "            X_train_cv, X_test_cv = self.X_train.iloc[train_index], self.X_train.iloc[test_index]\n",
    "            y_train_cv, y_test_cv = self.y_train.iloc[train_index], self.y_train.iloc[test_index] \n",
    "            apply = self.std_clf.score(X_train_cv, y_train_cv)\n",
    "            train_results.append(apply)\n",
    "        \n",
    "        self.train_results = train_results\n",
    "        return self.std_clf, self.train_scores, kf\n",
    "\n",
    "    def cv_model(self):\n",
    "        y_pred_train = cross_val_predict(self.std_clf, self.X_train, self.y_train, cv=self.kf)\n",
    "        \n",
    "        r2 = r2_score(self.y_train, y_pred_train)\n",
    "        mae = mean_absolute_error(self.y_train, y_pred_train)\n",
    "        rmse = np.sqrt(mean_squared_error(self.y_train, y_pred_train))\n",
    "        \n",
    "        cv_metrics = {'Initial_Model': self.selected_model,\n",
    "              \"Mean R^2\": r2, \n",
    "              \"Mean MAE\": mae,\n",
    "              \"Mean RMSE\": rmse}\n",
    "        return cv_metrics\n",
    "    \n",
    "    def validate_model(self, X_test, y_test):\n",
    "        y_pred = self.std_clf.predict(X_test)\n",
    "        \n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "        validation_metrics = {'Initial_Model': self.selected_model,\n",
    "              \"Mean R^2\": r2, \n",
    "              \"Mean MAE\": mae,\n",
    "              \"Mean RMSE\": rmse}\n",
    "        return validation_metrics\n",
    "\n",
    "    def test_model(self, X_test, y_test):\n",
    "        y_pred = self.std_clf.predict(X_test)\n",
    "        return y_pred\n",
    "    \n",
    "    def visualize_results(self, X_test, y_test, y_pred):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(32, 10))\n",
    "        plt.plot(y_test)\n",
    "        plt.plot(y_pred)\n",
    "        plt.xlabel(\"Date time\")\n",
    "        plt.ylabel(\"Price Elasticity of Demand\")\n",
    "        plt.xticks(np.arange(0, len(y_test), 20), rotation='vertical')\n",
    "        plt.show()\n",
    "\n",
    "    def initial_model_metrics(self, X_test, y_test, y_pred):\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "        initial_metrics = {'Initial_Model': self.selected_model,\n",
    "              \"Mean R^2\": r2, \n",
    "              \"Mean MAE\": mae,\n",
    "              \"Mean RMSE\": rmse}\n",
    "        return initial_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Initial Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24238194</td>\n",
       "      <td>2015-05-07 19:52:06.0000003</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06 UTC</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27835199</td>\n",
       "      <td>2009-07-17 20:04:56.0000002</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56 UTC</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44984355</td>\n",
       "      <td>2009-08-24 21:45:00.00000061</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00 UTC</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25894730</td>\n",
       "      <td>2009-06-26 08:22:21.0000001</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21 UTC</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17610152</td>\n",
       "      <td>2014-08-28 17:47:00.000000188</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00 UTC</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                            key  fare_amount  \\\n",
       "0    24238194    2015-05-07 19:52:06.0000003          7.5   \n",
       "1    27835199    2009-07-17 20:04:56.0000002          7.7   \n",
       "2    44984355   2009-08-24 21:45:00.00000061         12.9   \n",
       "3    25894730    2009-06-26 08:22:21.0000001          5.3   \n",
       "4    17610152  2014-08-28 17:47:00.000000188         16.0   \n",
       "\n",
       "           pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0  2015-05-07 19:52:06 UTC        -73.999817        40.738354   \n",
       "1  2009-07-17 20:04:56 UTC        -73.994355        40.728225   \n",
       "2  2009-08-24 21:45:00 UTC        -74.005043        40.740770   \n",
       "3  2009-06-26 08:22:21 UTC        -73.976124        40.790844   \n",
       "4  2014-08-28 17:47:00 UTC        -73.925023        40.744085   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0         -73.999512         40.723217                1  \n",
       "1         -73.994710         40.750325                1  \n",
       "2         -73.962565         40.772647                1  \n",
       "3         -73.965316         40.803349                3  \n",
       "4         -73.973082         40.761247                5  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_store[0]\n",
    "df0 = df_store[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0: int64\n",
      "key: object\n",
      "fare_amount: float64\n",
      "pickup_datetime: object\n",
      "pickup_longitude: float64\n",
      "pickup_latitude: float64\n",
      "dropoff_longitude: float64\n",
      "dropoff_latitude: float64\n",
      "passenger_count: int64\n"
     ]
    }
   ],
   "source": [
    "for col, dtype in zip(df.columns, df.dtypes):\n",
    "    print(f\"{col}: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Unnamed: 0', 'key', 'fare_amount', 'pickup_datetime','passenger_count']]\n",
    "frac = 0.01\n",
    "df_frac = len(df)*frac\n",
    "df = df.iloc[:int(df_frac),:]\n",
    "df0 = df0.iloc[:int(df_frac),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InspectData:\n",
    "    def __init__(self, raw_data, data, expected_dtypes, processed_dtypes, inspect_cols, eng_feature_cols, tagret_col):\n",
    "        self.raw_data = raw_data\n",
    "        self.data = data\n",
    "        self.expected_dtypes = expected_dtypes\n",
    "        self.processed_dtypes = processed_dtypes\n",
    "        self.inspect_cols = inspect_cols\n",
    "        self.eng_feature_cols = eng_feature_cols\n",
    "        self.target_col = target_col\n",
    "    \n",
    "    def inspection_1(self):\n",
    "        # BEFORE PREPROCESSING\n",
    "        \n",
    "        # Test 1: Ensure data is not empty\n",
    "        if self.data.empty:\n",
    "            raise ValueError('Inspection_1 Part 1 FAILURE: Input data is empty')\n",
    "        else:\n",
    "            print('Inspection_1 Part 1 PASS: Input data is not empty')\n",
    "\n",
    "        # Test 2: Check for missing values\n",
    "        if self.data.isnull().values.any():\n",
    "            return \"Inspection_1 Part 2 FAILURE: Input data contains missing values\"\n",
    "        else:\n",
    "            print('Inspection_1 Part 2 PASS: Data has no missing values')\n",
    "        \n",
    "        # Test 3: Check for NaN values    \n",
    "        if self.data.isna().values.any():\n",
    "            return \"Inspection_1 Part 3 FAILURE: Input data contains NaN values\"\n",
    "        else:\n",
    "            print('Inspection_1 Part 3 PASS: Data has no NaN values')\n",
    "        \n",
    "        # Test 4: Check for duplicate rows\n",
    "        if self.data.duplicated().any():\n",
    "            return \"Inspection_1 Part 4 CAUTION: Input data contains duplicate rows\"\n",
    "        else:\n",
    "            print(\"Inspection_1 Part 4 PASS: No duplicate rows found\")\n",
    "            \n",
    "        # Test 5: Ensure data types are as expected\n",
    "        mismatched_columns = []\n",
    "        for col, dtype in self.expected_dtypes.items():\n",
    "            if self.data[col].dtype != dtype:\n",
    "                mismatched_columns.append((col, self.data[col].dtype, dtype))\n",
    "        \n",
    "        if mismatched_columns:\n",
    "            column_info = '\\n'.join([f\"{col}: expected {expected}, got {actual}\" for col, actual, expected in mismatched_columns])\n",
    "            raise ValueError(f\"Inspection_1 Part 5 FAILURE: Columns {column_info}. Unexpected data types.\")\n",
    "        else:\n",
    "            print('Inspection_1 Part 5 PASS: All columns have expected data types')\n",
    "\n",
    "        outlier_cols = []\n",
    "        for col in self.inspect_cols:\n",
    "            z_score = np.abs((self.data[col] - self.data[col].mean()) / self.data[col].std())\n",
    "            if z_score.max() > 3:\n",
    "                outlier_cols.append(col)\n",
    "        if outlier_cols:\n",
    "            print(f\"Inspection_1 Part 6 CAUTION: Columns {outlier_cols} contain outliers\")\n",
    "        else:\n",
    "            print(\"Inspection_1 Part 6 PASS: No columns have outliers\")\n",
    "\n",
    "    def inspection_2(self):\n",
    "        \n",
    "        # Test 1: Outlier analysis\n",
    "        length_raw_data = len(self.raw_data)\n",
    "        length_data = len(self.data)\n",
    "        perc_change = length_data / length_raw_data\n",
    "        \n",
    "        if length_raw_data == length_data:\n",
    "            return print('Inspection_2 Part 1 FAILURE: Outliers have not been removed')\n",
    "        else:\n",
    "            print(f'Inspection_2 Part 1 PASS: Outliers removed, resultant dataset at {perc_change*100}%.')\n",
    "            \n",
    "        # Test 2: Check for missing values\n",
    "        if self.data.isnull().values.any():\n",
    "            return \"Inspection_2 Part 2 FAILURE: Input data contains missing values\"\n",
    "        else:\n",
    "            print('Inspection_2 Part 2 PASS: Data has no missing values')\n",
    "        \n",
    "        # Test 3: Check for NaN values    \n",
    "        if self.data.isna().values.any():\n",
    "            return \"Inspection_2 Part 3 FAILURE: Input data contains NaN values\"\n",
    "        else:\n",
    "            print('Inspection_2 Part 3 PASS: Data has no NaN values')\n",
    "        \n",
    "        # Test 4: Check for duplicate rows\n",
    "        if self.data.duplicated().any():\n",
    "            return \"Inspection_2 Part 4 CAUTION: Input data contains duplicate rows\"\n",
    "        else:\n",
    "            print(\"Inspection_2 Part 4 PASS: No duplicate rows found\")\n",
    "        \n",
    "        # Test 5: Check processed column dtypes are as expected\n",
    "        mismatched_columns = []\n",
    "        for col, dtype in self.processed_dtypes.items():\n",
    "            if self.data[col].dtype != dtype:\n",
    "                mismatched_columns.append((col, self.data[col].dtype, dtype))\n",
    "        \n",
    "        if mismatched_columns:\n",
    "            column_info = '\\n'.join([f\"{col}: expected {expected}, got {actual}\" for col, actual, expected in mismatched_columns])\n",
    "            raise ValueError(f\"Inspection_2 Part 2 FAILURE: Columns {column_info}. Unexpected data types.\")\n",
    "        else:\n",
    "            print('Inspection_2 Part 5 PASS: All columns have expected data types')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawDataTest(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        self.raw_data = pd.read_csv('C:/Users/delst/OneDrive - Queen Mary, University of London/Desktop/VSCode/Advanced_Projects/Uber_Demand_Project/data_archive/uber.csv')\n",
    "        self.data = self.raw_data[['Unnamed: 0', 'key', 'fare_amount', 'pickup_datetime','passenger_count']]\n",
    "        self.expected_dtypes = {\n",
    "                            'key': object,\n",
    "                            'fare_amount': float,\n",
    "                            'pickup_datetime': object,\n",
    "                            'passenger_count': np.int64\n",
    "                            }\n",
    "        self.processed_dtypes = {\n",
    "            'key': object,\n",
    "            'fare_amount': float,\n",
    "            'pickup_datetime': 'datetime64[ns]',\n",
    "            'passenger_count': np.int64,\n",
    "            'Label_Hour': np.int64,\n",
    "            'Label_Date': object,\n",
    "            'day_name': object,\n",
    "            'day_of_the_week': np.int64\n",
    "            }        \n",
    "\n",
    "        self.inspect_cols = [\n",
    "            'passenger_count', \n",
    "            'fare_amount'\n",
    "            ]     \n",
    "        \n",
    "    def test_inspection_1_part_1(self):\n",
    "        self.assertIsNotNone(self.data, \"Input data is empty\")\n",
    "        \n",
    "    def test_inspection_1_part_2(self):\n",
    "        self.assertFalse(self.data.isnull().values.any(), \"Input data contains missing values\")\n",
    "        \n",
    "    def test_inspection_1_part_3(self):\n",
    "        self.assertFalse(self.data.isna().values.any(), \"Input data contains NaN values\")\n",
    "        \n",
    "    def test_inspection_1_part_4(self):\n",
    "        self.assertFalse(self.data.duplicated().any(), \"Input data contains duplicate rows\")\n",
    "        \n",
    "    def test_inspection_1_part_5(self):\n",
    "        mismatched_columns = []\n",
    "        for col, dtype in self.expected_dtypes.items():\n",
    "            if self.data[col].dtype != dtype:\n",
    "                mismatched_columns.append((col, self.data[col].dtype, dtype))\n",
    "        \n",
    "        self.assertEqual(len(mismatched_columns), 0, f\"Columns {mismatched_columns} have unexpected data types\")\n",
    "        \n",
    "    def test_inspection_1_part_6(self):\n",
    "        outlier_cols = []\n",
    "        for col in self.inspect_cols:\n",
    "            z_score = np.abs((self.data[col] - self.data[col].mean()) / self.data[col].std())\n",
    "            if z_score.max() > 3:\n",
    "                outlier_cols.append(col)\n",
    "        self.assertEqual(len(outlier_cols), 0, f\"Columns {outlier_cols} have outliers\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawDataTest(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        self.raw_data = pd.read_csv('C:/Users/delst/OneDrive - Queen Mary, University of London/Desktop/VSCode/Advanced_Projects/Uber_Demand_Project/data_archive/uber.csv')\n",
    "        self.data = self.raw_data[['Unnamed: 0', 'key', 'fare_amount', 'pickup_datetime','passenger_count']]\n",
    "        self.data = Dataset(self.data, threshold=0.05).data_transform()\n",
    "        self.data = Dataset(self.data, threshold=0.05).data_remove_outliers()\n",
    "        self.expected_dtypes = {\n",
    "                            'key': object,\n",
    "                            'fare_amount': float,\n",
    "                            'pickup_datetime': object,\n",
    "                            'passenger_count': np.int64\n",
    "                            }\n",
    "        self.processed_dtypes = {\n",
    "            'key': object,\n",
    "            'fare_amount': float,\n",
    "            'pickup_datetime': 'datetime64[ns]',\n",
    "            'passenger_count': np.int64,\n",
    "            'Label_Hour': np.int64,\n",
    "            'Label_Date': object,\n",
    "            'day_name': object,\n",
    "            'day_of_the_week': np.int64\n",
    "            }        \n",
    "\n",
    "        self.inspect_cols = [\n",
    "            'passenger_count', \n",
    "            'fare_amount'\n",
    "            ]     \n",
    "        \n",
    "    def test_inspection_1_part_1(self):\n",
    "        self.assertIsNotNone(self.data, \"Input data is empty\")\n",
    "        \n",
    "    def test_inspection_1_part_2(self):\n",
    "        self.assertFalse(self.data.isnull().values.any(), \"Input data contains missing values\")\n",
    "        \n",
    "    def test_inspection_1_part_3(self):\n",
    "        self.assertFalse(self.data.isna().values.any(), \"Input data contains NaN values\")\n",
    "        \n",
    "    def test_inspection_1_part_4(self):\n",
    "        self.assertFalse(self.data.duplicated().any(), \"Input data contains duplicate rows\")\n",
    "        \n",
    "    def test_inspection_1_part_5(self):\n",
    "        mismatched_columns = []\n",
    "        for col, dtype in self.expected_dtypes.items():\n",
    "            if self.data[col].dtype != dtype:\n",
    "                mismatched_columns.append((col, self.data[col].dtype, dtype))\n",
    "        \n",
    "        self.assertEqual(len(mismatched_columns), 0, f\"Columns {mismatched_columns} have unexpected data types\")\n",
    "        \n",
    "    def test_inspection_1_part_6(self):\n",
    "        outlier_cols = []\n",
    "        for col in self.inspect_cols:\n",
    "            z_score = np.abs((self.data[col] - self.data[col].mean()) / self.data[col].std())\n",
    "            if z_score.max() > 3:\n",
    "                outlier_cols.append(col)\n",
    "        self.assertEqual(len(outlier_cols), 0, f\"Columns {outlier_cols} have outliers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = df0\n",
    "data = df\n",
    "\n",
    "expected_dtypes = {\n",
    "    'key': object,\n",
    "    'fare_amount': float,\n",
    "    'pickup_datetime': object,\n",
    "    'passenger_count': np.int64\n",
    "    }\n",
    "\n",
    "processed_dtypes = {\n",
    "    'key': object,\n",
    "    'fare_amount': float,\n",
    "    'pickup_datetime': 'datetime64[ns]',\n",
    "    'passenger_count': np.int64,\n",
    "    'Label_Hour': np.int64,\n",
    "    'Label_Date': object,\n",
    "    'day_name': object,\n",
    "    'day_of_the_week': np.int64\n",
    "    }\n",
    "\n",
    "inspect_cols = [\n",
    "    'passenger_count', \n",
    "    'fare_amount'\n",
    "    ]\n",
    "\n",
    "col_group = ['pickup_datetime', 'fare_amount', 'passenger_count','Label_Date']   # Group by columns\n",
    "col_feature = ['fare_amount', 'passenger_count']   # Feature extraction columns\n",
    "input_columns = ['sPED']\n",
    "target_col = 'sPED'\n",
    "\n",
    "eng_feature_cols = ['fare_amount_pct_change', 'passenger_count_pct_change', \n",
    "                    'passenger_count_pct_change_sma', 'fare_amount_pct_change_sma'\n",
    "                    ]\n",
    "\n",
    "n_window = 3\n",
    "threshold = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising Pipeline...\n",
      "\n",
      "Inspecting Raw data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....FF\n",
      "======================================================================\n",
      "FAIL: test_inspection_1_part_5 (__main__.RawDataTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\delst\\AppData\\Local\\Temp/ipykernel_22408/2801617373.py\", line 48, in test_inspection_1_part_5\n",
      "    self.assertEqual(len(mismatched_columns), 0, f\"Columns {mismatched_columns} have unexpected data types\")\n",
      "AssertionError: 1 != 0 : Columns [('pickup_datetime', dtype('<M8[ns]'), <class 'object'>)] have unexpected data types\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_inspection_1_part_6 (__main__.RawDataTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\delst\\AppData\\Local\\Temp/ipykernel_22408/2801617373.py\", line 56, in test_inspection_1_part_6\n",
      "    self.assertEqual(len(outlier_cols), 0, f\"Columns {outlier_cols} have outliers\")\n",
      "AssertionError: 2 != 0 : Columns ['passenger_count', 'fare_amount'] have outliers\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 266.474s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data...\n",
      "\n",
      "Inspecting Processed data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ProcessedDataTest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22408/3855841712.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msuite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mdata_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpected_dtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minspect_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mdata_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22408/3855841712.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(raw_data, expected_dtypes, inspect_cols)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nInspecting Processed data...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mtest_inspector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProcessedDataTest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mtest_inspector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetUp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0msuite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munittest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTestLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadTestsFromModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_inspector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ProcessedDataTest' is not defined"
     ]
    }
   ],
   "source": [
    "def pipeline(raw_data, expected_dtypes, inspect_cols):\n",
    "\n",
    "    print('Initialising Pipeline...')\n",
    "\n",
    "    print('\\nInspecting Raw data...')\n",
    "    test_inspector = RawDataTest()\n",
    "    test_inspector.setUp()\n",
    "    suite = unittest.TestLoader().loadTestsFromModule(test_inspector)\n",
    "    unittest.TextTestRunner().run(suite)\n",
    "\n",
    "    print('\\nProcessing data...')\n",
    "    dataset = Dataset(raw_data, threshold=0.05)\n",
    "    data = dataset.data_transform()\n",
    "    data = dataset.data_remove_outliers()\n",
    "    \n",
    "    print('\\nInspecting Processed data...')\n",
    "    test_inspector = ProcessedDataTest()\n",
    "    test_inspector.setUp()\n",
    "    suite = unittest.TestLoader().loadTestsFromModule(test_inspector)\n",
    "    unittest.TextTestRunner().run(suite)\n",
    "\n",
    "    return suite\n",
    "\n",
    "data_output = pipeline(data, expected_dtypes, inspect_cols)\n",
    "data_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26b6c9d81eee416a7009d4e9cab3f891edd865043d5e75db037808610cbf1dcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
